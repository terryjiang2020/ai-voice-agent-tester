#!/usr/bin/env python3
"""
TTS æœåŠ¡ - åŸºäº CosyVoice (é˜¿é‡Œå¼€æº)
æ”¯æŒæµå¼è¯­éŸ³åˆæˆä¸å¤šè¯­è¨€
"""

import asyncio
import os
from typing import AsyncGenerator
import numpy as np
from loguru import logger

try:
    import torch
    import torchaudio
except ImportError:
    logger.warning("PyTorch not installed, TTS service will not work")
    torch = None


class TTSService:
    """TTS è¯­éŸ³åˆæˆæœåŠ¡"""
    
    def __init__(self):
        self.model = None
        self.model_name = os.getenv(
            "TTS_MODEL",
            "CosyVoice-300M"  # è½»é‡æ¨¡å‹ï¼Œé€‚åˆå®æ—¶æ¨ç†
        )
        self.use_cpu = os.getenv("USE_CPU", "0") == "1"
        self.sample_rate = 24000  # CosyVoice è¾“å‡º 24kHz
        
        # æµå¼ç”Ÿæˆé…ç½®
        self.chunk_size = 1024  # æ¯ä¸ªéŸ³é¢‘å—çš„æ ·æœ¬æ•°
        
    async def load_model(self):
        """åŠ è½½ TTS æ¨¡å‹"""
        if torch is None:
            raise RuntimeError("PyTorch not installed. Run: pip install torch torchaudio")
        
        logger.info(f"Loading TTS model: {self.model_name}")
        
        try:
            # æ£€æŸ¥ CosyVoice æ˜¯å¦å·²å®‰è£…
            try:
                from cosyvoice.cli.cosyvoice import CosyVoice
            except ImportError:
                raise RuntimeError(
                    "CosyVoice not installed. Please install:\n"
                    "  cd backend\n"
                    "  git clone https://github.com/FunAudioLLM/CosyVoice.git\n"
                    "  cd CosyVoice && pip install -e ."
                )
            
            # è®¾ç½®è®¾å¤‡
            device = "cpu" if self.use_cpu else "cuda"
            if device == "cuda" and not torch.cuda.is_available():
                logger.warning("CUDA not available, falling back to CPU")
                device = "cpu"
            
            # åŠ è½½æ¨¡å‹
            model_dir = f"pretrained_models/{self.model_name}"
            
            # å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œæä¾›ä¸‹è½½æç¤º
            if not os.path.exists(model_dir):
                logger.warning(
                    f"Model not found at {model_dir}\n"
                    "Please download the model:\n"
                    "  cd backend\n"
                    "  git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M\n"
                )
                raise FileNotFoundError(f"Model directory not found: {model_dir}")
            
            self.model = CosyVoice(model_dir)
            self.device = device
            
            logger.success(f"âœ… TTS model loaded on {device}")
            
        except Exception as e:
            logger.error(f"Failed to load TTS model: {e}")
            raise
    
    async def synthesize_stream(
        self, 
        text: str,
        voice: str = "ä¸­æ–‡å¥³",
        speed: float = 1.0
    ) -> AsyncGenerator[bytes, None]:
        """
        æµå¼è¯­éŸ³åˆæˆ
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice: éŸ³è‰² (é¢„è®¾éŸ³è‰²æˆ–è‡ªå®šä¹‰)
            speed: è¯­é€Ÿ (0.5-2.0)
            
        Yields:
            éŸ³é¢‘æ•°æ®å— (PCM 24kHz mono)
        """
        if self.model is None:
            raise RuntimeError("TTS model not loaded")
        
        try:
            logger.info(f"Synthesizing: {text[:50]}...")
            
            # æ–‡æœ¬åˆ†æ®µ (æŒ‰å¥å­)
            sentences = self._split_text(text)
            
            for sentence in sentences:
                if not sentence.strip():
                    continue
                
                # åˆæˆéŸ³é¢‘ (åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ)
                audio_chunks = await asyncio.to_thread(
                    self._synthesize_sentence,
                    sentence,
                    voice,
                    speed
                )
                
                # æµå¼è¿”å›éŸ³é¢‘å—
                for chunk in audio_chunks:
                    yield chunk
                    
        except Exception as e:
            logger.error(f"TTS synthesis error: {e}")
            raise
    
    def _split_text(self, text: str) -> list:
        """æ–‡æœ¬åˆ†å¥"""
        # ç®€å•åˆ†å¥ç­–ç•¥
        separators = ["ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?", "\n"]
        
        sentences = []
        current = ""
        
        for char in text:
            current += char
            if char in separators:
                sentences.append(current.strip())
                current = ""
        
        if current.strip():
            sentences.append(current.strip())
        
        return sentences
    
    def _synthesize_sentence(
        self,
        text: str,
        voice: str,
        speed: float
    ) -> list:
        """åˆæˆå•ä¸ªå¥å­ (åŒæ­¥æ–¹æ³•)"""
        try:
            # CosyVoice æ¨ç†
            # æ³¨æ„: å®é™… API å¯èƒ½ä¸åŒï¼Œéœ€æ ¹æ® CosyVoice æ–‡æ¡£è°ƒæ•´
            output = self.model.inference_sft(
                text=text,
                spk_id=voice,
                speed=speed,
            )
            
            # æå–éŸ³é¢‘æ•°æ®
            if isinstance(output, dict) and "tts_speech" in output:
                audio_tensor = output["tts_speech"]
            else:
                audio_tensor = output
            
            # è½¬æ¢ä¸º numpy
            audio_np = audio_tensor.cpu().numpy()
            
            # ç¡®ä¿å•å£°é“
            if audio_np.ndim > 1:
                audio_np = audio_np.mean(axis=0)
            
            # è½¬æ¢ä¸º int16 PCM
            audio_int16 = (audio_np * 32767).astype(np.int16)
            
            # åˆ†å—
            chunks = []
            for i in range(0, len(audio_int16), self.chunk_size):
                chunk = audio_int16[i:i + self.chunk_size]
                chunks.append(chunk.tobytes())
            
            return chunks
            
        except Exception as e:
            logger.error(f"Sentence synthesis error: {e}")
            # è¿”å›ç©ºéŸ³é¢‘å—
            return [b'\x00' * self.chunk_size * 2]
    
    async def synthesize_to_file(
        self,
        text: str,
        output_file: str,
        voice: str = "ä¸­æ–‡å¥³"
    ):
        """åˆæˆéŸ³é¢‘æ–‡ä»¶ (éæµå¼)"""
        if self.model is None:
            raise RuntimeError("TTS model not loaded")
        
        try:
            # æ”¶é›†æ‰€æœ‰éŸ³é¢‘å—
            audio_chunks = []
            async for chunk in self.synthesize_stream(text, voice):
                audio_chunks.append(chunk)
            
            # åˆå¹¶éŸ³é¢‘
            audio_bytes = b''.join(audio_chunks)
            audio_np = np.frombuffer(audio_bytes, dtype=np.int16)
            
            # ä¿å­˜ä¸º WAV
            audio_float = audio_np.astype(np.float32) / 32768.0
            audio_tensor = torch.from_numpy(audio_float).unsqueeze(0)
            
            torchaudio.save(
                output_file,
                audio_tensor,
                self.sample_rate
            )
            
            logger.success(f"Audio saved to {output_file}")
            
        except Exception as e:
            logger.error(f"File synthesis error: {e}")
            raise
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.model:
            del self.model
            self.model = None
        
        if torch and torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        logger.info("TTS service cleaned up")


# ============================================
# ğŸ™ï¸ ä½¿ç”¨ç¤ºä¾‹
# ============================================
"""
# åˆå§‹åŒ–
tts = TTSService()
await tts.load_model()

# æµå¼åˆæˆ
async for audio_chunk in tts.synthesize_stream("ä½ å¥½ï¼Œä¸–ç•Œï¼"):
    # å‘é€éŸ³é¢‘å—ç»™å®¢æˆ·ç«¯
    await websocket.send_bytes(audio_chunk)

# æ–‡ä»¶åˆæˆ
await tts.synthesize_to_file("æµ‹è¯•æ–‡æœ¬", "output.wav")
"""
