#!/usr/bin/env python3
"""
ASR æœåŠ¡ - åŸºäº FunASR (é˜¿é‡Œå¼€æº)
æ”¯æŒå®æ—¶æµå¼è¯­éŸ³è¯†åˆ«
"""

import asyncio
import os
from typing import AsyncGenerator, Dict, Optional
import numpy as np
from loguru import logger

try:
    from funasr import AutoModel
    from modelscope.hub.snapshot_download import snapshot_download
    try:
        # å¯é€‰çš„ Hugging Face å…œåº•ä¸‹è½½
        from huggingface_hub import snapshot_download as hf_snapshot_download
    except Exception:
        hf_snapshot_download = None
except ImportError:
    logger.warning("FunASR not installed, ASR service will not work")
    AutoModel = None


class ASRService:
    """ASR è¯­éŸ³è¯†åˆ«æœåŠ¡"""
    
    def __init__(self):
        self.model = None
        self.model_name = os.getenv(
            "ASR_MODEL",
            "iic/SenseVoiceNano"  # Fun-ASR Nano æ¨¡å‹ï¼ˆæ›´å¿«ï¼‰
        )
        self.use_cpu = os.getenv("USE_CPU", "0") == "1"
        self.sample_rate = 16000  # Fun-ASR è¦æ±‚ 16kHz
        
        # æµå¼å¤„ç†ç¼“å†²åŒº
        self.audio_buffer = []
        self.buffer_duration_ms = 200  # æ¯ 200ms å¤„ç†ä¸€æ¬¡
        
    async def load_model(self):
        """åŠ è½½ ASR æ¨¡å‹"""
        if AutoModel is None:
            raise RuntimeError("FunASR not installed. Run: pip install funasr modelscope")
        
        logger.info(f"Loading ASR model: {self.model_name}")
        
        try:
            # ä¸‹è½½æ¨¡å‹ (é¦–æ¬¡è¿è¡Œ)
            model_dir = None
            try:
                model_dir = snapshot_download(self.model_name)
                logger.info(f"Model downloaded to (ModelScope): {model_dir}")
            except Exception as ms_err:
                logger.warning(f"ModelScope download failed for {self.model_name}: {ms_err}")
                # å½“ä½¿ç”¨ ModelScope è·¯å¾„å¤±è´¥æ—¶ï¼Œå›é€€åˆ° Hugging Face ä¸Šçš„å…¬å¼€æ¨¡å‹
                if hf_snapshot_download:
                    fallback = os.getenv("ASR_MODEL_FALLBACK", "FunAudioLLM/SenseVoiceSmall")
                    try:
                        model_dir = hf_snapshot_download(fallback)
                        # å°†æ¨¡å‹ååˆ‡æ¢ä¸º Hugging Face æ ‡è¯†ï¼Œä¾¿äº AutoModel åŠ è½½
                        self.model_name = fallback
                        logger.info(f"Model downloaded to (HuggingFace): {model_dir}")
                    except Exception as hf_err:
                        logger.error(f"HuggingFace fallback download failed for {fallback}: {hf_err}")
                        raise
                else:
                    raise
            
            # åŠ è½½æ¨¡å‹
            device = "cpu" if self.use_cpu else "cuda"
            self.model = AutoModel(
                model=self.model_name,
                trust_remote_code=True,
                device=device,
                ncpu=4 if self.use_cpu else 1,
                # æµå¼æ¨ç†é…ç½®
                batch_size=1,
            )
            
            logger.success(f"âœ… ASR model loaded on {device}")
            
        except Exception as e:
            logger.error(f"Failed to load ASR model: {e}")
            raise
    
    async def transcribe_stream(
        self, 
        audio_chunk: bytes
    ) -> Optional[Dict]:
        """
        æµå¼è¯­éŸ³è¯†åˆ«
        
        Args:
            audio_chunk: éŸ³é¢‘æ•°æ® (PCM 16kHz mono)
            
        Returns:
            {
                "text": "è¯†åˆ«æ–‡æœ¬",
                "is_final": False,  # æ˜¯å¦æ˜¯æœ€ç»ˆç»“æœ
                "confidence": 0.95
            }
        """
        if self.model is None:
            raise RuntimeError("ASR model not loaded")
        
        try:
            # è½¬æ¢ä¸º numpy array
            audio_np = np.frombuffer(audio_chunk, dtype=np.int16)
            audio_float = audio_np.astype(np.float32) / 32768.0
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            self.audio_buffer.append(audio_float)
            
            # è®¡ç®—ç¼“å†²åŒºæ—¶é•¿
            total_samples = sum(len(buf) for buf in self.audio_buffer)
            duration_ms = (total_samples / self.sample_rate) * 1000
            
            # å¦‚æœç¼“å†²åŒºä¸è¶³ï¼Œè¿”å›ç©º
            if duration_ms < self.buffer_duration_ms:
                return None
            
            # åˆå¹¶ç¼“å†²åŒº
            audio_data = np.concatenate(self.audio_buffer)
            self.audio_buffer = []
            
            # ASR æ¨ç†
            result = await asyncio.to_thread(
                self._run_inference,
                audio_data
            )
            
            return result
            
        except Exception as e:
            logger.error(f"ASR transcription error: {e}")
            return None
    
    def _run_inference(self, audio_data: np.ndarray) -> Dict:
        """åŒæ­¥æ¨ç†æ–¹æ³• (åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ)"""
        try:
            # FunASR æ¨ç†
            res = self.model.generate(
                input=audio_data,
                batch_size=1,
                language="auto",  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
                use_itn=True,     # ä½¿ç”¨é€†æ–‡æœ¬å½’ä¸€åŒ–
            )
            
            if res and len(res) > 0:
                text = res[0].get("text", "")
                
                # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ç»ˆç»“æœ (ç®€å•ç­–ç•¥: æ–‡æœ¬é•¿åº¦ > 3)
                is_final = len(text) > 3
                
                return {
                    "text": text,
                    "is_final": is_final,
                    "confidence": 0.9,  # FunASR ä¸ç›´æ¥æä¾›ç½®ä¿¡åº¦
                    "language": res[0].get("lang", "zh"),
                }
            
            return None
            
        except Exception as e:
            logger.error(f"Inference error: {e}")
            return None
    
    async def transcribe_file(self, audio_file: str) -> str:
        """è½¬å†™éŸ³é¢‘æ–‡ä»¶ (éæµå¼)"""
        if self.model is None:
            raise RuntimeError("ASR model not loaded")
        
        try:
            result = await asyncio.to_thread(
                self.model.generate,
                input=audio_file,
                batch_size=1,
                language="auto",
                use_itn=True,
            )
            
            if result and len(result) > 0:
                return result[0].get("text", "")
            
            return ""
            
        except Exception as e:
            logger.error(f"File transcription error: {e}")
            return ""
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.audio_buffer = []
        if self.model:
            del self.model
            self.model = None
        logger.info("ASR service cleaned up")


# ============================================
# ğŸ¤ ä½¿ç”¨ç¤ºä¾‹
# ============================================
"""
# åˆå§‹åŒ–
asr = ASRService()
await asr.load_model()

# æµå¼è¯†åˆ«
audio_chunk = b'...'  # PCM 16kHz mono
result = await asr.transcribe_stream(audio_chunk)
if result:
    print(f"è¯†åˆ«: {result['text']}, æœ€ç»ˆ: {result['is_final']}")

# æ–‡ä»¶è¯†åˆ«
text = await asr.transcribe_file("audio.wav")
print(f"æ–‡æœ¬: {text}")
"""
