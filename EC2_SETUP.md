# EC2 GPU éƒ¨ç½²æŒ‡å—ï¼ˆæœ¬åœ°è¿è¡Œæ¨¡å¼ï¼‰

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•åœ¨ AWS EC2 GPU å®ä¾‹ä¸Šç›´æ¥è¿è¡Œè¯­éŸ³å¯¹è¯ç³»ç»Ÿï¼ˆä¸ä½¿ç”¨ Dockerï¼‰ã€‚

## ğŸ–¥ EC2 å®ä¾‹è¦æ±‚

### æ¨èé…ç½®
- **å®ä¾‹ç±»å‹**: `g4dn.xlarge` æˆ–æ›´é«˜ï¼ˆNVIDIA T4 GPUï¼‰
- **AMI**: Deep Learning AMI GPU PyTorch 2.0+ (Ubuntu 22.04)
- **å­˜å‚¨**: è‡³å°‘ 50GB SSD
- **å®‰å…¨ç»„**: å¼€æ”¾ç«¯å£ 8000ï¼ˆåç«¯ï¼‰ã€5173ï¼ˆå‰ç«¯ï¼‰

### æœ€ä½é…ç½®
- **CPU**: 4 æ ¸å¿ƒ
- **å†…å­˜**: 16GB
- **GPU**: NVIDIA GPU with CUDA 11.8+
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 22.04 LTS

---

## ğŸ“¦ 1. ç³»ç»Ÿä¾èµ–å®‰è£…

### 1.1 æ›´æ–°ç³»ç»Ÿ
```bash
sudo apt update && sudo apt upgrade -y
```

### 1.2 å®‰è£… Python 3.10+
```bash
sudo apt install -y python3.10 python3.10-venv python3-pip
python3 --version  # ç¡®è®¤ç‰ˆæœ¬
```

### 1.3 å®‰è£… NVIDIA é©±åŠ¨å’Œ CUDAï¼ˆå¦‚æœæœªé¢„è£…ï¼‰
```bash
# æ£€æŸ¥ CUDA
nvidia-smi

# å¦‚æœæœªå®‰è£…ï¼Œä½¿ç”¨ Deep Learning AMI æˆ–æ‰‹åŠ¨å®‰è£… CUDA 11.8
# https://developer.nvidia.com/cuda-downloads
```

### 1.4 å®‰è£… FFmpeg å’ŒéŸ³é¢‘åº“
```bash
sudo apt install -y ffmpeg libsndfile1 git
```

### 1.5 å®‰è£… Node.js 18+
```bash
curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
sudo apt install -y nodejs
node --version  # ç¡®è®¤ç‰ˆæœ¬
```

---

## ğŸ¦™ 2. å®‰è£… Ollama

```bash
# å®‰è£… Ollama
curl -fsSL https://ollama.com/install.sh | sh

# å¯åŠ¨ Ollama æœåŠ¡ï¼ˆåå°è¿è¡Œï¼‰
nohup ollama serve > ollama.log 2>&1 &

# æ‹‰å–æ¨¡å‹
ollama pull qwen3:0.6b

# éªŒè¯
ollama list
```

---

## ğŸ¯ 3. å…‹éš†å’Œé…ç½®é¡¹ç›®

### 3.1 å…‹éš†ä»“åº“
```bash
cd ~
git clone https://github.com/terryjiang2020/ai-voice-agent-tester.git
cd ai-voice-agent-tester
```

### 3.2 é…ç½®ç¯å¢ƒå˜é‡
```bash
cp .env.example .env
nano .env
```

ç¡®ä¿ä»¥ä¸‹é…ç½®æ­£ç¡®ï¼š
```bash
# æœ¬åœ° Ollama
USE_LOCAL_LLM=1
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=qwen3:0.6b

# æ¨¡å‹é…ç½®
ASR_MODEL=iic/SenseVoiceNano
TTS_MODEL=CosyVoice-300M

# GPU æ¨¡å¼
USE_CPU=0

# å‰ç«¯ WebSocket
VITE_BACKEND_WS=ws://<YOUR_EC2_PUBLIC_IP>:8000/ws
```

**é‡è¦**: å°† `<YOUR_EC2_PUBLIC_IP>` æ›¿æ¢ä¸ºä½ çš„ EC2 å…¬ç½‘ IPã€‚

---

## ğŸ 4. å®‰è£… Python åç«¯

### 4.1 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
cd backend
python3 -m venv venv
source venv/bin/activate
```

### 4.2 å®‰è£…ä¾èµ–
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4.3 å®‰è£… CosyVoiceï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰
```bash
# æ–¹å¼ 1ï¼šä» ModelScope å…‹éš†
git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M

# æ–¹å¼ 2ï¼šä» Hugging Face å…‹éš†ï¼ˆå›½é™…ç½‘ç»œæ›´å¿«ï¼‰
git lfs install
git clone https://huggingface.co/FunAudioLLM/CosyVoice-300M pretrained_models/CosyVoice-300M
```

### 4.4 å®‰è£… CosyVoice ä»£ç åº“
```bash
# å…‹éš† CosyVoice ä»“åº“
git clone https://github.com/FunAudioLLM/CosyVoice.git
cd CosyVoice
pip install -e .
cd ..
```

---

## âš¡ 5. å¯åŠ¨æœåŠ¡

### 5.1 ä½¿ç”¨è‡ªåŠ¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰
```bash
cd ~/ai-voice-agent-tester
chmod +x scripts/start-local.sh
./scripts/start-local.sh
```

### 5.2 æ‰‹åŠ¨å¯åŠ¨

#### å¯åŠ¨åç«¯
```bash
cd ~/ai-voice-agent-tester/backend
source venv/bin/activate
python server.py
```

åç«¯å°†åœ¨ `http://0.0.0.0:8000` å¯åŠ¨ã€‚

#### å¯åŠ¨å‰ç«¯ï¼ˆæ–°ç»ˆç«¯ï¼‰
```bash
cd ~/ai-voice-agent-tester
npm install
npm run dev
```

å‰ç«¯å°†åœ¨ `http://0.0.0.0:5173` å¯åŠ¨ã€‚

---

## ğŸŒ 6. è®¿é—®åº”ç”¨

### ä»æœ¬åœ°æµè§ˆå™¨è®¿é—®
```
http://<YOUR_EC2_PUBLIC_IP>:5173
```

### SSH ç«¯å£è½¬å‘ï¼ˆå¦‚æœç«¯å£æœªå¼€æ”¾ï¼‰
```bash
# åœ¨æœ¬åœ°æœºå™¨æ‰§è¡Œ
ssh -L 5173:localhost:5173 -L 8000:localhost:8000 ubuntu@<EC2_IP>
```

ç„¶åè®¿é—® `http://localhost:5173`

---

## ğŸ”§ 7. éªŒè¯å®‰è£…

### 7.1 æ£€æŸ¥ GPU
```bash
nvidia-smi
```

åº”è¯¥çœ‹åˆ° GPU ä½¿ç”¨ç‡ä¸Šå‡ï¼ˆå½“æ¨¡å‹åŠ è½½æ—¶ï¼‰ã€‚

### 7.2 æ£€æŸ¥åç«¯å¥åº·
```bash
curl http://localhost:8000/health
```

åº”è¯¥è¿”å› `{"status": "ok"}`ã€‚

### 7.3 æ£€æŸ¥ Ollama
```bash
curl http://localhost:11434/v1/models
```

åº”è¯¥çœ‹åˆ° `qwen3:0.6b` åœ¨æ¨¡å‹åˆ—è¡¨ä¸­ã€‚

### 7.4 æµ‹è¯• ASR æ¨¡å‹åŠ è½½
```python
from funasr import AutoModel

model = AutoModel(
    model="iic/SenseVoiceNano",
    trust_remote_code=True,
    device="cuda"
)
print("âœ… ASR model loaded successfully")
```

---

## ğŸš€ 8. ç”Ÿäº§ç¯å¢ƒé…ç½®

### 8.1 ä½¿ç”¨ systemd è‡ªåŠ¨å¯åŠ¨

#### åç«¯æœåŠ¡
```bash
sudo nano /etc/systemd/system/voice-backend.service
```

å†…å®¹ï¼š
```ini
[Unit]
Description=Voice Agent Backend
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/ai-voice-agent-tester/backend
Environment="PATH=/home/ubuntu/ai-voice-agent-tester/backend/venv/bin"
ExecStart=/home/ubuntu/ai-voice-agent-tester/backend/venv/bin/python server.py
Restart=always

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨ï¼š
```bash
sudo systemctl daemon-reload
sudo systemctl enable voice-backend
sudo systemctl start voice-backend
sudo systemctl status voice-backend
```

#### å‰ç«¯æœåŠ¡
```bash
sudo nano /etc/systemd/system/voice-frontend.service
```

å†…å®¹ï¼š
```ini
[Unit]
Description=Voice Agent Frontend
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/ai-voice-agent-tester
ExecStart=/usr/bin/npm run dev
Restart=always

[Install]
WantedBy=multi-user.target
```

### 8.2 ä½¿ç”¨ Nginx åå‘ä»£ç†
```bash
sudo apt install -y nginx

sudo nano /etc/nginx/sites-available/voice-agent
```

å†…å®¹ï¼š
```nginx
server {
    listen 80;
    server_name <YOUR_DOMAIN>;

    location / {
        proxy_pass http://localhost:5173;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
    }

    location /ws {
        proxy_pass http://localhost:8000/ws;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "Upgrade";
        proxy_set_header Host $host;
    }
}
```

å¯ç”¨ï¼š
```bash
sudo ln -s /etc/nginx/sites-available/voice-agent /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx
```

---

## ğŸ“Š 9. æ€§èƒ½ä¼˜åŒ–

### 9.1 GPU æ˜¾å­˜ä¼˜åŒ–
```bash
# è®¾ç½® PyTorch æ˜¾å­˜åˆ†é…ç­–ç•¥
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
```

### 9.2 æ¨¡å‹é‡åŒ–ï¼ˆå¯é€‰ï¼‰
å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œå¯ä»¥ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬ï¼š
```bash
# ASR ä½¿ç”¨ INT8 é‡åŒ–
ASR_MODEL=iic/SenseVoiceNano-int8

# Ollama ä½¿ç”¨é‡åŒ–æ¨¡å‹
ollama pull qwen3:0.6b-q4_0
```

### 9.3 å¹¶å‘ä¼˜åŒ–
åœ¨ `.env` ä¸­è°ƒæ•´ï¼š
```bash
WORKERS=2  # æ ¹æ® GPU æ•°é‡è°ƒæ•´
BATCH_SIZE=4  # æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´
```

---

## ğŸ› 10. å¸¸è§é—®é¢˜

### CUDA Out of Memory
```bash
# å‡å°‘æ‰¹å¤„ç†å¤§å°
export BATCH_SIZE=1

# æˆ–ä½¿ç”¨ CPU æ¨¡å¼ï¼ˆå¤‡ç”¨ï¼‰
export USE_CPU=1
```

### Ollama è¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
ps aux | grep ollama

# é‡å¯æœåŠ¡
pkill ollama
nohup ollama serve > ollama.log 2>&1 &
```

### CosyVoice æ¨¡å‹æœªæ‰¾åˆ°
```bash
ls -la backend/pretrained_models/CosyVoice-300M
# å¦‚æœä¸ºç©ºï¼Œé‡æ–°ä¸‹è½½æ¨¡å‹
```

### ç«¯å£è¢«å ç”¨
```bash
# æŸ¥æ‰¾å ç”¨ç«¯å£çš„è¿›ç¨‹
sudo lsof -i :8000
sudo lsof -i :5173

# æ€æ­»è¿›ç¨‹
sudo kill -9 <PID>
```

---

## ğŸ“ 11. ç›‘æ§å’Œæ—¥å¿—

### æŸ¥çœ‹åç«¯æ—¥å¿—
```bash
tail -f ~/ai-voice-agent-tester/backend/logs/app.log
```

### æŸ¥çœ‹ Ollama æ—¥å¿—
```bash
tail -f ~/ollama.log
```

### GPU ç›‘æ§
```bash
watch -n 1 nvidia-smi
```

---

## ğŸ” 12. å®‰å…¨å»ºè®®

1. **é˜²ç«å¢™é…ç½®**: ä»…å¼€æ”¾å¿…è¦ç«¯å£ï¼ˆ80/443/22ï¼‰
2. **HTTPS**: ä½¿ç”¨ Let's Encrypt é…ç½® SSL
3. **API å¯†é’¥**: ä¸è¦å°†æ•æ„Ÿå¯†é’¥æäº¤åˆ° Git
4. **SSH å¯†é’¥**: ç¦ç”¨å¯†ç ç™»å½•ï¼Œä»…ä½¿ç”¨ SSH å¯†é’¥

---

## ğŸ“š 13. ç›¸å…³èµ„æº

- [Fun-ASR æ–‡æ¡£](https://github.com/alibaba-damo-academy/FunASR)
- [CosyVoice æ–‡æ¡£](https://github.com/FunAudioLLM/CosyVoice)
- [Ollama æ–‡æ¡£](https://ollama.com/docs)
- [AWS EC2 GPU å®ä¾‹](https://aws.amazon.com/ec2/instance-types/g4/)

---

## ğŸ‰ å®Œæˆï¼

ç°åœ¨ä½ çš„ EC2 GPU å®ä¾‹å·²ç»é…ç½®å¥½æœ¬åœ°è¿è¡Œæ¨¡å¼ï¼Œå¯ä»¥ï¼š
- âœ… ä½¿ç”¨æœ¬åœ° GPU åŠ é€Ÿ ASR/TTS
- âœ… ä½¿ç”¨æœ¬åœ° Ollama (qwen3:0.6b) è¿›è¡Œå¯¹è¯
- âœ… æ— éœ€ Docker å¼€é”€ï¼Œæ€§èƒ½æ›´ä¼˜
- âœ… å®Œå…¨æœ¬åœ°æ¨ç†ï¼Œæ•°æ®éšç§æœ‰ä¿éšœ
