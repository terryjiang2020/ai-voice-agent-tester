# EC2 å¿«é€Ÿå¯åŠ¨æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆå·²é…ç½®å¥½ EC2ï¼‰

å¦‚æœä½ çš„ EC2 å·²ç»å®‰è£…å¥½æ‰€æœ‰ä¾èµ–ï¼Œå¿«é€Ÿå¯åŠ¨ï¼š

```bash
# 1. å¯åŠ¨ Ollamaï¼ˆåå°ï¼‰
nohup ollama serve > ollama.log 2>&1 &

# 2. ç¡®è®¤æ¨¡å‹å·²ä¸‹è½½
ollama list  # åº”è¯¥çœ‹åˆ° qwen3:0.6b

# 3. å¯åŠ¨åº”ç”¨
cd ~/ai-voice-agent-tester
./scripts/start-local.sh
```

è®¿é—®: `http://<EC2_IP>:5173`

---

## ğŸ“‹ EC2 ä¸Šéœ€è¦çš„æ–‡ä»¶å’Œæ¨¡å‹

### å¿…éœ€æ¨¡å‹ä½ç½®
```
~/ai-voice-agent-tester/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ pretrained_models/
â”‚   â”‚   â””â”€â”€ CosyVoice-300M/          # TTS æ¨¡å‹ï¼ˆçº¦ 1GBï¼‰
â”‚   â”œâ”€â”€ CosyVoice/                    # CosyVoice ä»£ç åº“
â”‚   â””â”€â”€ venv/                         # Python è™šæ‹Ÿç¯å¢ƒ
â””â”€â”€ .env                              # é…ç½®æ–‡ä»¶
```

### Ollama æ¨¡å‹
```bash
ollama pull qwen3:0.6b  # LLM æ¨¡å‹ï¼ˆçº¦ 400MBï¼‰
```

### Fun-ASR æ¨¡å‹
ä¼šåœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä» ModelScope ä¸‹è½½åˆ°ï¼š
```
~/.cache/modelscope/models/iic/SenseVoiceNano/
```

---

## ğŸ”§ ç¯å¢ƒå˜é‡é…ç½®ï¼ˆ.envï¼‰

```bash
# Ollamaï¼ˆæœ¬åœ°ï¼‰
USE_LOCAL_LLM=1
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=qwen3:0.6b

# æ¨¡å‹
ASR_MODEL=iic/SenseVoiceNano
TTS_MODEL=CosyVoice-300M

# GPU
USE_CPU=0

# ç½‘ç»œï¼ˆé‡è¦ï¼šå¡«å†™ EC2 å…¬ç½‘ IPï¼‰
VITE_BACKEND_WS=ws://YOUR_EC2_PUBLIC_IP:8000/ws
```

---

## ğŸ¯ æ‰‹åŠ¨å¯åŠ¨ï¼ˆåˆ†æ­¥ï¼‰

### 1. å¯åŠ¨ Ollama
```bash
# æ£€æŸ¥æ˜¯å¦å·²è¿è¡Œ
ps aux | grep ollama

# å¦‚æœæ²¡è¿è¡Œï¼Œå¯åŠ¨
nohup ollama serve > ollama.log 2>&1 &
```

### 2. å¯åŠ¨åç«¯
```bash
cd ~/ai-voice-agent-tester/backend
source venv/bin/activate
python server.py
```

### 3. å¯åŠ¨å‰ç«¯ï¼ˆæ–°ç»ˆç«¯ï¼‰
```bash
cd ~/ai-voice-agent-tester
npm run dev -- --host 0.0.0.0
```

---

## âœ… éªŒè¯æ£€æŸ¥

### GPU æ£€æŸ¥
```bash
nvidia-smi
# åº”è¯¥çœ‹åˆ° GPU ä¿¡æ¯å’Œä½¿ç”¨ç‡
```

### Ollama æ£€æŸ¥
```bash
curl http://localhost:11434/v1/models
# åº”è¯¥è¿”å› qwen3:0.6b
```

### åç«¯å¥åº·æ£€æŸ¥
```bash
curl http://localhost:8000/health
# åº”è¯¥è¿”å› {"status": "ok"}
```

### æ¨¡å‹æ–‡ä»¶æ£€æŸ¥
```bash
# CosyVoice
ls backend/pretrained_models/CosyVoice-300M/

# Fun-ASRï¼ˆé¦–æ¬¡è¿è¡Œåï¼‰
ls ~/.cache/modelscope/models/iic/SenseVoiceNano/
```

---

## ğŸ› å¸¸è§é—®é¢˜å¿«é€Ÿä¿®å¤

### Ollama è¿æ¥å¤±è´¥
```bash
pkill ollama
nohup ollama serve > ollama.log 2>&1 &
```

### ç«¯å£è¢«å ç”¨
```bash
# æŸ¥æ‰¾å¹¶æ€æ­»è¿›ç¨‹
sudo lsof -i :8000  # åç«¯
sudo lsof -i :5173  # å‰ç«¯
sudo kill -9 <PID>
```

### GPU æœªä½¿ç”¨
```bash
# æ£€æŸ¥ .env
cat .env | grep USE_CPU  # åº”è¯¥æ˜¯ 0

# æ£€æŸ¥ CUDA
python -c "import torch; print(torch.cuda.is_available())"
```

### CosyVoice æ¨¡å‹æœªæ‰¾åˆ°
```bash
cd ~/ai-voice-agent-tester/backend
git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M
```

---

## ğŸ“Š æ€§èƒ½ç›‘æ§

### å®æ—¶ GPU ç›‘æ§
```bash
watch -n 1 nvidia-smi
```

### åç«¯æ—¥å¿—
```bash
tail -f ~/ai-voice-agent-tester/backend/logs/app.log
```

### Ollama æ—¥å¿—
```bash
tail -f ~/ollama.log
```

---

## ğŸ”„ æ›´æ–°ä»£ç 

```bash
cd ~/ai-voice-agent-tester
git pull origin main

# é‡æ–°å®‰è£…ä¾èµ–ï¼ˆå¦‚æœæœ‰æ›´æ–°ï¼‰
cd backend
source venv/bin/activate
pip install -r requirements.txt

cd ..
npm install

# é‡å¯æœåŠ¡
./scripts/start-local.sh
```

---

## ğŸ›‘ åœæ­¢æœåŠ¡

```bash
# åœæ­¢å‰ç«¯ï¼ˆCtrl+C åœ¨è¿è¡Œç»ˆç«¯ï¼‰

# åœæ­¢åç«¯
pkill -f "python server.py"

# åœæ­¢ Ollama
pkill ollama
```

---

## ğŸ‰ å®Œæ•´å‘½ä»¤åºåˆ—ï¼ˆå…¨æ–°å®‰è£…ï¼‰

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/terryjiang2020/ai-voice-agent-tester.git
cd ai-voice-agent-tester

# 2. é…ç½®ç¯å¢ƒ
cp .env.example .env
nano .env  # ä¿®æ”¹ VITE_BACKEND_WS

# 3. å®‰è£… Ollama å’Œæ¨¡å‹
curl -fsSL https://ollama.com/install.sh | sh
ollama pull qwen3:0.6b

# 4. å®‰è£… Python ä¾èµ–
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 5. å®‰è£… CosyVoice
git clone https://github.com/FunAudioLLM/CosyVoice.git
cd CosyVoice && pip install -e . && cd ..
git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M

# 6. å®‰è£…å‰ç«¯ä¾èµ–
cd ..
npm install

# 7. å¯åŠ¨
./scripts/start-local.sh
```

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ `EC2_SETUP.md`ã€‚
