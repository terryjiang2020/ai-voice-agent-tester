#!/bin/bash
set -e

echo "ðŸš€ Starting Local Voice Agent (EC2 GPU Mode)..."
echo ""

# æ£€æŸ¥ Python
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python3 not found. Please install Python 3.10+"
    exit 1
fi

# æ£€æŸ¥ Node.js
if ! command -v node &> /dev/null; then
    echo "âŒ Node.js not found. Please install Node.js 18+"
    exit 1
fi

# æ£€æŸ¥ Ollama
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama not found. Please install Ollama first:"
    echo "   curl -fsSL https://ollama.com/install.sh | sh"
    exit 1
fi

# æ£€æŸ¥ Ollama æœåŠ¡
echo "ðŸ¦™ Checking Ollama service..."
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âš ï¸  Ollama service not running. Starting..."
    echo "   Please run in another terminal: ollama serve"
    echo ""
    read -p "   Press Enter when Ollama is running..."
fi

# æ£€æŸ¥æ¨¡åž‹
OLLAMA_MODEL=$(grep "^OLLAMA_MODEL=" .env 2>/dev/null | cut -d'=' -f2 || echo "qwen3:0.6b")
echo "   Checking model: $OLLAMA_MODEL"
if ! ollama list | grep -q "$OLLAMA_MODEL"; then
    echo "âš ï¸  Model $OLLAMA_MODEL not found."
    echo "   Downloading (this may take a few minutes)..."
    ollama pull "$OLLAMA_MODEL"
fi

echo "âœ… Ollama ready: $OLLAMA_MODEL"
echo ""

# æ£€æŸ¥ .env
if [ ! -f ".env" ]; then
    echo "âš ï¸  .env file not found. Creating from template..."
    cp .env.example .env
    echo "âœ… Created .env - Please edit with your API keys if needed"
fi

# æ£€æŸ¥ Python ä¾èµ–
echo "ðŸ“¦ Checking Python dependencies..."
cd backend
if [ ! -d "venv" ]; then
    echo "   Creating virtual environment..."
    python3 -m venv venv
fi

source venv/bin/activate
pip install -q -r requirements.txt

echo "âœ… Python environment ready"
echo ""

# æ£€æŸ¥ CUDA
if command -v nvidia-smi &> /dev/null; then
    echo "ðŸŽ® GPU detected:"
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader
    echo ""
fi

# æ£€æŸ¥ CosyVoice æ¨¡åž‹
if [ ! -d "pretrained_models/CosyVoice-300M" ]; then
    echo "âš ï¸  CosyVoice model not found at pretrained_models/CosyVoice-300M"
    echo ""
    echo "Please download the model:"
    echo "   cd backend"
    echo "   git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M"
    echo ""
    read -p "Press Enter to continue (or Ctrl+C to exit)..."
fi

# å¯åŠ¨åŽç«¯
echo "ðŸ Starting Python backend..."
python server.py &
BACKEND_PID=$!

cd ..

# ç­‰å¾…åŽç«¯å¯åŠ¨
echo "â³ Waiting for backend to initialize..."
for i in {1..30}; do
    if curl -s http://localhost:8000/health > /dev/null 2>&1; then
        echo "âœ… Backend ready"
        break
    fi
    sleep 1
done

# æ£€æŸ¥ Node ä¾èµ–
echo "ðŸ“¦ Checking Node.js dependencies..."
if [ ! -d "node_modules" ]; then
    npm install
fi

# å¯åŠ¨å‰ç«¯
echo "âš¡ Starting frontend..."
npm run dev

# æ¸…ç†
trap "kill $BACKEND_PID 2>/dev/null" EXIT
